{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: 10 pts - For the function\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{x^{2}}{1+x^{4}}, ~ -1 \\leq x \\leq 1\n",
    "$$\n",
    "\n",
    "a) (2pts) Using an equispaced set of $10$ nodes, generate the Lagrange interpolating polynomial to $f(x)$.  Generate a plot which shows how the error in your approximation varies over the interval.  \n",
    "\n",
    "b) (2pts) Using an equispaced set of $20$ nodes, generate the Lagrange interpolating polynomial to $f(x)$.  Generate a plot which shows how the error in your approximation varies over the interval.  \n",
    "\n",
    "c) (2pts) At what number of equispaced nodes does your Lagrange interpolation approximation break down?  \n",
    "\n",
    "d) (4pts) Does using Chebyshev points help resolve the issues you saw in c) ?  Provide examples to verify your claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: 10 pts - In class, we showed that if interpolated over three points, say $x_{j-1}$, $x_{j}$, $x_{j+1}$, with data $f_{j-1}$, $f_{j}$, and $f_{j+1}$, where our nodes are equally spaced so that \n",
    "\n",
    "$$\n",
    "\\delta x = x_{j+1} - x_{j} = x_{j} - x_{j-1}\n",
    "$$\n",
    "\n",
    "then using $f(x)\\approx P_{2}(x)$, we have \n",
    "\n",
    "$$\n",
    "f'(x_{j}) \\approx \\frac{f_{j+1}-f_{j-1}}{2\\delta x}\n",
    "$$\n",
    "\n",
    "This is known as a _centered difference_ approximation to a derivative of a function.  \n",
    "\n",
    "* (3 pts) Using the same interpolation information, find an approximation to $f''(x_{j})$.  \n",
    "* (3 pts) Using $f(x) = \\cos(x)$, determine the accuracy of your centered difference approximations with respect to the magnitude of $\\delta x$ for both the first and second derivatives.  In other words, if we suppose that \n",
    "$$\n",
    "f'(x_{j}) = \\frac{f_{j+1}-f_{j-1}}{2\\delta x} + C\\delta x^{p},\n",
    "$$\n",
    "then find $p$.  Clearly explain your methodology.  \n",
    "* (4 pts) Derive a centered difference approximation for $f'(x_{j})$ and $f''(x_{j})$ using the equally spaced nodes $x_{j-2}$, $x_{j-1}$, $x_{j}$, $x_{j+1}$, $x_{j+2}$, with corresponding node spacing $\\delta x$, and corresponding data $f_{j-2}$, $f_{j-1}$, $f_{j}$, $f_{j+1}$, $f_{j+2}$.  Determine the order of accuracy of your approximation again using $f(x) = \\cos(x)$.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the error in our approximation, we look at points $x_{j}\\in[0, 2\\pi]$ where $\\delta x = 2\\pi/N$ so that\n",
    "\n",
    "$$\n",
    "x_{j} = \\frac{2\\pi j}{N}, ~j=0, \\cdots, N.\n",
    "$$\n",
    "\n",
    "We plot the maximum of the absolute value of the error in our approximation over our chosen interval for increasing choices of $N$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
