{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25893f43",
   "metadata": {},
   "source": [
    "## Centered Divided Differences\n",
    "\n",
    "As we've already shown when we discussed Simpson's method, if we interpolate between three pairs of points, say $(x_{j-1},f_{j-1})$, $(x_{j},f_{j})$, $(x_{j+1},f_{j+1})$, where $\\delta x = x_{j}-x_{j-1}$, with the parabola\n",
    "\n",
    "$$\n",
    "y_{j}(x) = a_{j}(x-x_{j})^{2} + b_{j}(x-x_{j}) + c_{j}\n",
    "$$\n",
    "\n",
    "then we have that $c_{j}=f_{j}$ and \n",
    "\n",
    "$$\n",
    "a_{j} = \\frac{1}{2(\\delta x)^{2}}\\left(f_{j+1} -2f_{j} + f_{j-1}\\right), ~ b_{j} = \\frac{1}{2\\delta x}\\left(f_{j+1} -f_{j-1} \\right)\n",
    "$$\n",
    "\n",
    "Using Taylor series arguments, we see that\n",
    "\n",
    "\\begin{align*}\n",
    "f_{j+1} = f(x_{j} + \\delta x) = & f_{j} + f'(x_{j})\\delta x + \\frac{1}{2}f''(x_{j}) (\\delta x)^{2} + \\frac{1}{6}f'''(x_{j})(\\delta x)^{3} + \\frac{1}{24}f''''(x_{j})(\\delta x)^{4} + \\mathcal{O}((\\delta x )^{5})\\\\ \n",
    "f_{j-1} = f(x_{j} - \\delta x) = & f_{j} - f'(x_{j})\\delta x + \\frac{1}{2}f''(x_{j}) (\\delta x)^{2} - \\frac{1}{6}f'''(x_{j})(\\delta x)^{3} + \\frac{1}{24}f''''(x_{j})(\\delta x)^{4} + \\mathcal{O}((\\delta x )^{5})\\\\ \n",
    "\\end{align*}\n",
    "\n",
    "Using these we then see that\n",
    "\n",
    "$$\n",
    "\\frac{1}{2\\delta x}\\left(f_{j+1} -f_{j-1} \\right) = \\frac{1}{2\\delta x}\\left(2f'(x_{j})\\delta x + \\frac{1}{3}f'''(x_{j})(\\delta x)^{3} + \\mathcal{O}((\\delta x)^{5})\\right)\n",
    "$$\n",
    "\n",
    "so under rearrangement, we have the approximation to $f'(x_{j})$\n",
    "\n",
    "$$\n",
    "f'(x_{j}) = \\frac{1}{2\\delta x}\\left(f_{j+1} -f_{j-1} \\right) - \\frac{1}{6}f'''(x_{j})(\\delta x)^{2} + \\mathcal{O}((\\delta x)^{4})\n",
    "$$\n",
    "\n",
    "We likewise can show that \n",
    "\n",
    "$$\n",
    "f''(x_{j}) = \\frac{1}{(\\delta x)^{2}}\\left(f_{j+1} -2f_{j} + f_{j-1}\\right) - \\frac{1}{12}f''''(x_{j})(\\delta x)^{2} + \\mathcal{O}((\\delta x)^{3}).\n",
    "$$\n",
    "\n",
    "Thus, we see that we have found a way to discretize the first and second derivatives such that the error goes like $\\mathcal{O}((\\delta x)^{2})$, and so we call these second-order accurate approximations.  We also describe them as _centered_ due to the symmetry of how we build the approximation.  \n",
    "\n",
    "Okay,  fine, but let's see what this really means.  Our test function will be $f(x)=\\sin(x)$ so that $f'(x)=\\cos(x)$.  To test our approximation, we then use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e98792",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = lambda x: np.sin(x)\n",
    "dfun = lambda x: np.cos(x)\n",
    "Nvals = np.array([1e1, 1e2, 1e3, 1e4, 1e5])\n",
    "Errors = np.zeros(np.size(Nvals))\n",
    "\n",
    "for jj in range(np.size(Nvals)):\n",
    "    xvals = np.linspace(0.,1.,int(Nvals[jj])+1)\n",
    "    fvals = fun(xvals)\n",
    "    dftrue = dfun(xvals)\n",
    "    \n",
    "    fplus = fvals[2:]\n",
    "    fminus = fvals[:-2]\n",
    "    fprime = (fplus-fminus)/(2.*(xvals[1]-xvals[0]))\n",
    "    Errors[jj] = np.max(np.abs(fprime - dftrue[1:-1]))\n",
    "    \n",
    "plt.plot(np.log10(Nvals), np.log10(Errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0959153",
   "metadata": {},
   "source": [
    "## General Divided Differences\n",
    "\n",
    "So, we in some sense stumbled upon the above derivative approximations.  How might we be more systematic about doing this?  And what happens if we want derivative approximations which are not centered?  Then what?  \n",
    "\n",
    "This is where our general Lagrange interpolation approach becomes really powerful.  In general, if I give you data $\\left\\{x_{j},f_{j}\\right\\}_{j=0}^{n}$, then from the approximating interoplating polynomial $p_{n}(x)\\approx f(x)$ where \n",
    "\n",
    "$$\n",
    "p_{n}(x) = \\sum_{j=0}^{n}f_{j}L_{j}(x),\n",
    "$$\n",
    "\n",
    "then we can approximate $f'(x_{j})\\approx p_{n}'(x_{j})$.\n",
    "\n",
    "### Off-Centered Approximations\n",
    "\n",
    "### Higher-Order Centered Approximations\n",
    "\n",
    "### Derivatives using Chebyshev Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca3d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
